{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generators(img_size = 448):\n",
    "    # This function loads the generator for the test.\n",
    "    # This first approach takes the test images from the disk\n",
    "    \n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    img_size = 448\n",
    "    test_dir = 'C:/Users/julen/OneDrive/Escritorio/IA/CS577-Deep-Learning/Project/images'\n",
    "    batch = 16\n",
    "\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                      target_size = (img_size,img_size),\n",
    "                                                      batch_size = batch,\n",
    "                                                       shuffle = False,\n",
    "                                                       class_mode = 'categorical')\n",
    "    \n",
    "    return(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(train, directory):\n",
    "    # This function loads the images, resizes them and puts them into an array\n",
    "    \n",
    "    img_size = 448\n",
    "    train_image = []\n",
    "    for name in train['image_id']:\n",
    "        path = directory + name + '.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        train_image.append(img)\n",
    "    train_image_array = np.array(train_image)\n",
    "    \n",
    "    return train_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generator_flow():\n",
    "    # This function loads the generator for the test.\n",
    "    # This second approach takes the test images from the memory\n",
    "    \n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    \n",
    "    directory_data = 'C:/Users/julen/OneDrive/Escritorio/IA/CS577-Deep-Learning/Project/Data/'\n",
    "    df_test = pd.read_csv(directory_data + 'test.csv')\n",
    "    directory_images = 'C:/Users/julen/OneDrive/Escritorio/IA/CS577-Deep-Learning/Project/images/'\n",
    "    x_test = load_images(df_test, directory_images)\n",
    "    \n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "    test_generator = test_datagen.flow(x_test, batch_size = 4,\n",
    "                                       #target_size = (224,224),\n",
    "                                       shuffle = False)\n",
    "                                       #classes = ['CROP'])\n",
    "    \n",
    "    return(df_test, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer, InputSpec\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "class GlobalKMaxPooling2D(Layer): #Inherits the properties of Layer class\n",
    "    # Implements GlobalKMaxPooling, as it is needed for uploading the model\n",
    "    \n",
    "    def __init__(self, data_format=None, k = 10, **kwargs):\n",
    "        super(GlobalKMaxPooling2D, self).__init__(**kwargs)\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            return (input_shape[0], input_shape[3])\n",
    "        else:\n",
    "            return (input_shape[0], input_shape[1])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'data_format': self.data_format, 'k' : self.k}\n",
    "        base_config = super(GlobalKMaxPooling2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.data_format == 'channels_last':\n",
    "            k = self.k\n",
    "\n",
    "            input_reshaped = tf.reshape(inputs, [tf.shape(inputs)[0], -1, tf.shape(inputs)[3]])\n",
    "            input_reshaped = tf.reshape(input_reshaped, [tf.shape(input_reshaped)[0], tf.shape(input_reshaped)[2], tf.shape(input_reshaped)[1]])\n",
    "            top_k = tf.math.top_k(input_reshaped, k=k, sorted = True, name = None)[0]\n",
    "            mean = tf.keras.backend.mean(top_k, axis = 2)\n",
    "            #assert ((input_reshaped.get_shape()[0], input_reshaped.get_shape()[-1]) == mean.get_shape())\n",
    "        \n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name_json, name_h5):\n",
    "    # This function loads the trained model\n",
    "    \n",
    "    json_file = open(name_json + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json, custom_objects = {'GlobalKMaxPooling2D': GlobalKMaxPooling2D})\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(name_h5 + \".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(model, test_generator, name):\n",
    "    # This function does the prediction, modifies the test datafrane and saves it\n",
    "    \n",
    "    x_pred = model.predict_generator(test_generator, verbose = 1)\n",
    "    df_test['healthy'] = x_pred[:,0]\n",
    "    df_test['multiple_diseases'] = x_pred[:,1]\n",
    "    df_test['rust'] = x_pred[:,2]\n",
    "    df_test['scab'] = x_pred[:,3]\n",
    "    df_test.to_csv(name, index = None)\n",
    "    print('Prediction saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "directory_load = 'C:/Users/julen/OneDrive/Escritorio/IA/CS577-Deep-Learning/Project/Models/'\n",
    "name_load_h5 = 'Elope_xception_V2_best_model'\n",
    "name_load_json = 'Elope_xception_V3_flow'\n",
    "\n",
    "model = load_model(name_json = directory_load + name_load_json, name_h5 = directory_load + name_load_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456/456 [==============================] - 39s 86ms/step\n",
      "[[8.31219740e-03 1.11466283e-02 9.80273604e-01 2.67632131e-04]\n",
      " [8.76260237e-05 3.83779668e-04 9.99526501e-01 2.20245738e-06]\n",
      " [1.97638190e-04 3.07090324e-03 3.49942384e-05 9.96696472e-01]\n",
      " ...\n",
      " [5.39765169e-04 2.39205151e-03 9.97014284e-01 5.37835440e-05]\n",
      " [9.86957788e-01 7.32123805e-03 8.77724553e-04 4.84323082e-03]\n",
      " [5.22935239e-04 8.09589773e-03 1.19286546e-04 9.91261959e-01]]\n",
      "Prediction saved\n"
     ]
    }
   ],
   "source": [
    "df_test, test_generator = load_generator_flow()\n",
    "predict_and_save(model, test_generator, name = 'Elope_xception_V3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.980274</td>\n",
       "      <td>0.000268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_1</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_2</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.996696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_3</td>\n",
       "      <td>0.998264</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_4</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.973199</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Test_1816</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.996771</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Test_1817</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.995471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Test_1818</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.997014</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Test_1819</td>\n",
       "      <td>0.986958</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.004843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>Test_1820</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.991262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id   healthy  multiple_diseases      rust      scab\n",
       "0        Test_0  0.008312           0.011147  0.980274  0.000268\n",
       "1        Test_1  0.000088           0.000384  0.999527  0.000002\n",
       "2        Test_2  0.000198           0.003071  0.000035  0.996696\n",
       "3        Test_3  0.998264           0.000166  0.000362  0.001208\n",
       "4        Test_4  0.007931           0.018639  0.973199  0.000231\n",
       "...         ...       ...                ...       ...       ...\n",
       "1816  Test_1816  0.001388           0.001787  0.996771  0.000054\n",
       "1817  Test_1817  0.000887           0.003594  0.000048  0.995471\n",
       "1818  Test_1818  0.000540           0.002392  0.997014  0.000054\n",
       "1819  Test_1819  0.986958           0.007321  0.000878  0.004843\n",
       "1820  Test_1820  0.000523           0.008096  0.000119  0.991262\n",
       "\n",
       "[1821 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "directory = 'C:/Users/julen/OneDrive/Escritorio/IA/CS577-Deep-Learning/Project/Predictions/'\n",
    "df_1 = pd.read_csv(directory + 'Best_score.csv')\n",
    "df_2 = pd.read_csv(directory + 'Elope_probe_V1.csv')\n",
    "df_3 = pd.read_csv(directory + 'Elope_xception_V3.csv')\n",
    "df_total = df_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['healthy'] = (df_1['healthy'] + df_2['healthy'] + df_3['healthy']) / 3\n",
    "df_total['multiple_diseases'] = (df_1['multiple_diseases'] + df_2['multiple_diseases'] + df_3['multiple_diseases']) / 3\n",
    "df_total['rust'] = (df_1['rust'] + df_2['rust'] + df_3['rust']) / 3\n",
    "df_total['scab'] = (df_1['scab'] + df_2['scab'] + df_3['scab']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv('Ensembling.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv('Ensembling_optimized.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
